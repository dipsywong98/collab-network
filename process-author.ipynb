{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocess the authors\n",
    "\n",
    "This notebook aims to preprocess the author data and save to shelve database,\n",
    "as well as testing the read write functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Import libraries and set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "\n",
    "data_cache_prefix = 'data_cache/'\n",
    "\n",
    "database_file = data_cache_prefix+\"author.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The database functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to a SQLite database \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        print(sqlite3.version)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "def create_table(conn, create_table_sql):\n",
    "    \"\"\" create a table from the create_table_sql statement\n",
    "    :param conn: Connection object\n",
    "    :param create_table_sql: a CREATE TABLE statement\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(create_table_sql)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "def create_author_table(conn):\n",
    "    sql_create_authors_table = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS authors (\n",
    "            id integer PRIMARY KEY,\n",
    "            idx text,\n",
    "            n text NOT NULL,\n",
    "            a text NOT NULL,\n",
    "            pc integer ,\n",
    "            cn integer,\n",
    "            hi integer,\n",
    "            pi REAL,\n",
    "            upi REAL,\n",
    "            t text\n",
    "        );\n",
    "        \"\"\"\n",
    "    create_table(conn, sql_create_authors_table)\n",
    "\n",
    "def create_author(conn, author):\n",
    "    sql = \"\"\"\n",
    "    INSERT INTO authors (idx,n,a,pc,cn,hi,pi,upi,t) VALUES (?,?,?,?,?,?,?,?,?)\n",
    "    \"\"\"\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql, author)\n",
    "    return cur.lastrowid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Put all authors to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "processed 0/1712434\n",
      "processed 10000/1712434\n",
      "processed 20000/1712434\n",
      "processed 30000/1712434\n",
      "processed 40000/1712434\n",
      "processed 50000/1712434\n",
      "processed 60000/1712434\n",
      "processed 70000/1712434\n",
      "processed 80000/1712434\n",
      "processed 90000/1712434\n",
      "processed 100000/1712434\n",
      "processed 110000/1712434\n",
      "processed 120000/1712434\n",
      "processed 130000/1712434\n",
      "processed 140000/1712434\n",
      "processed 150000/1712434\n",
      "processed 160000/1712434\n",
      "processed 170000/1712434\n",
      "processed 180000/1712434\n",
      "processed 190000/1712434\n",
      "processed 200000/1712434\n",
      "processed 210000/1712434\n",
      "processed 220000/1712434\n",
      "processed 230000/1712434\n",
      "processed 240000/1712434\n",
      "processed 250000/1712434\n",
      "processed 260000/1712434\n",
      "processed 270000/1712434\n",
      "processed 280000/1712434\n",
      "processed 290000/1712434\n",
      "processed 300000/1712434\n",
      "processed 310000/1712434\n",
      "processed 320000/1712434\n",
      "processed 330000/1712434\n",
      "processed 340000/1712434\n",
      "processed 350000/1712434\n",
      "processed 360000/1712434\n",
      "processed 370000/1712434\n",
      "processed 380000/1712434\n",
      "processed 390000/1712434\n",
      "processed 400000/1712434\n",
      "processed 410000/1712434\n",
      "processed 420000/1712434\n",
      "processed 430000/1712434\n",
      "processed 440000/1712434\n",
      "processed 450000/1712434\n",
      "processed 460000/1712434\n",
      "processed 470000/1712434\n",
      "processed 480000/1712434\n",
      "processed 490000/1712434\n",
      "processed 500000/1712434\n",
      "processed 510000/1712434\n",
      "processed 520000/1712434\n",
      "processed 530000/1712434\n",
      "processed 540000/1712434\n",
      "processed 550000/1712434\n",
      "processed 560000/1712434\n",
      "processed 570000/1712434\n",
      "processed 580000/1712434\n",
      "processed 590000/1712434\n",
      "processed 600000/1712434\n",
      "processed 610000/1712434\n",
      "processed 620000/1712434\n",
      "processed 630000/1712434\n",
      "processed 640000/1712434\n",
      "processed 650000/1712434\n",
      "processed 660000/1712434\n",
      "processed 670000/1712434\n",
      "processed 680000/1712434\n",
      "processed 690000/1712434\n",
      "processed 700000/1712434\n",
      "processed 710000/1712434\n",
      "processed 720000/1712434\n",
      "processed 730000/1712434\n",
      "processed 740000/1712434\n",
      "processed 750000/1712434\n",
      "processed 760000/1712434\n",
      "processed 770000/1712434\n",
      "processed 780000/1712434\n",
      "processed 790000/1712434\n",
      "processed 800000/1712434\n",
      "processed 810000/1712434\n",
      "processed 820000/1712434\n",
      "processed 830000/1712434\n",
      "processed 840000/1712434\n",
      "processed 850000/1712434\n",
      "processed 860000/1712434\n",
      "processed 870000/1712434\n",
      "processed 880000/1712434\n",
      "processed 890000/1712434\n",
      "processed 900000/1712434\n",
      "processed 910000/1712434\n",
      "processed 920000/1712434\n",
      "processed 930000/1712434\n",
      "processed 940000/1712434\n",
      "processed 950000/1712434\n",
      "processed 960000/1712434\n",
      "processed 970000/1712434\n",
      "processed 980000/1712434\n",
      "processed 990000/1712434\n",
      "processed 1000000/1712434\n",
      "processed 1010000/1712434\n",
      "processed 1020000/1712434\n",
      "processed 1030000/1712434\n",
      "processed 1040000/1712434\n",
      "processed 1050000/1712434\n",
      "processed 1060000/1712434\n",
      "processed 1070000/1712434\n",
      "processed 1080000/1712434\n",
      "processed 1090000/1712434\n",
      "processed 1100000/1712434\n",
      "processed 1110000/1712434\n",
      "processed 1120000/1712434\n",
      "processed 1130000/1712434\n",
      "processed 1140000/1712434\n",
      "processed 1150000/1712434\n",
      "processed 1160000/1712434\n",
      "processed 1170000/1712434\n",
      "processed 1180000/1712434\n",
      "processed 1190000/1712434\n",
      "processed 1200000/1712434\n",
      "processed 1210000/1712434\n",
      "processed 1220000/1712434\n",
      "processed 1230000/1712434\n",
      "processed 1240000/1712434\n",
      "processed 1250000/1712434\n",
      "processed 1260000/1712434\n",
      "processed 1270000/1712434\n",
      "processed 1280000/1712434\n",
      "processed 1290000/1712434\n",
      "processed 1300000/1712434\n",
      "processed 1310000/1712434\n",
      "processed 1320000/1712434\n",
      "processed 1330000/1712434\n",
      "processed 1340000/1712434\n",
      "processed 1350000/1712434\n",
      "processed 1360000/1712434\n",
      "processed 1370000/1712434\n",
      "processed 1380000/1712434\n",
      "processed 1390000/1712434\n",
      "processed 1400000/1712434\n",
      "processed 1410000/1712434\n",
      "processed 1420000/1712434\n",
      "processed 1430000/1712434\n",
      "processed 1440000/1712434\n",
      "processed 1450000/1712434\n",
      "processed 1460000/1712434\n",
      "processed 1470000/1712434\n",
      "processed 1480000/1712434\n",
      "processed 1490000/1712434\n",
      "processed 1500000/1712434\n",
      "processed 1510000/1712434\n",
      "processed 1520000/1712434\n",
      "processed 1530000/1712434\n",
      "processed 1540000/1712434\n",
      "processed 1550000/1712434\n",
      "processed 1560000/1712434\n",
      "processed 1570000/1712434\n",
      "processed 1580000/1712434\n",
      "processed 1590000/1712434\n",
      "processed 1600000/1712434\n",
      "processed 1610000/1712434\n",
      "processed 1620000/1712434\n",
      "processed 1630000/1712434\n",
      "processed 1640000/1712434\n",
      "processed 1650000/1712434\n",
      "processed 1660000/1712434\n",
      "processed 1670000/1712434\n",
      "processed 1680000/1712434\n",
      "processed 1690000/1712434\n",
      "processed 1700000/1712434\n",
      "processed 1710000/1712434\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#index 1\n",
    "#n O. Willum\n",
    "#a Res. Center for Microperipherik, Technische Univ. Berlin, Germany\n",
    "#pc 1\n",
    "#cn 0\n",
    "#hi 0\n",
    "#pi 0.0000\n",
    "#upi 0.0000\n",
    "#t new product;product group;active product;long product lifetime;old product;product generation;new technology;environmental benefit;environmental choice;environmental consequence\n",
    "'''\n",
    "def process_author_sqlite():\n",
    "    with open('data/AMiner-Author.txt', 'r') as file:\n",
    "        data = file.read().split('\\n\\n')\n",
    "\n",
    "    database = data_cache_prefix+\"author.db\"\n",
    "    conn = create_connection(database)\n",
    "\n",
    "    # create tables\n",
    "    if conn is None:\n",
    "        # create projects table\n",
    "        print(\"Error! cannot create the database connection.\")\n",
    "    else:\n",
    "        with conn:\n",
    "            create_author_table(conn)\n",
    "\n",
    "            detail = ['index', 'n', 'a', 'pc', 'cn', 'hi', 'pi', 'upi', 't']\n",
    "            total = len(data)\n",
    "            for n, auth in enumerate(data):\n",
    "                info = auth.split('\\n')\n",
    "                if info[0] is '':\n",
    "                    break\n",
    "                index = info[0].split(' ')[1]\n",
    "                author = [0,0,0,0,0,0,0,0,0]\n",
    "                for num,each in enumerate(detail):\n",
    "                    author[num] = info[num].replace('#'+each+' ', '')\n",
    "                create_author(conn, author)\n",
    "                if n % 10000 == 0:\n",
    "                    print(\"processed %d/%d\"%(n,total))\n",
    "    conn.close()\n",
    "\n",
    "process_author_sqlite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Query the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['61', '121', '137', '200', '239', '326', '445', '545', '618', '665']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter(keyword, by_type):\n",
    "    with create_connection(database_file) as conn:\n",
    "        rows = conn.cursor().execute(\n",
    "            f\"\"\"\n",
    "            SELECT idx FROM authors WHERE {by_type} LIKE '%'||?||'%'\n",
    "            \"\"\"\n",
    "        ,[keyword]).fetchall()\n",
    "        return [row[0] for row in rows]\n",
    "\n",
    "filter('math','t')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "query by index\n",
      "[(12345, '12345', 'Brendan Johnson', '', 1, 7, 1, 1.0, 0.1429, 'Xen guest;Xen hypervisor;O Employing Xen;Xen LiveCD;Xen Project Leader VP;Xen Security Modules;Xen Utilizing Xen security;Xen Virtualization;Xen community;Xen implementation')]\n",
      "query by tag\n",
      "[(61, '61', 'Xinping Yan', '', 1, 0, 0, 0.0, 0.0, 'GP algorithm;F-W algorithm;FW algorithm;mathematic model;traffic assignment model;different engine operating mode;different location;different network structure;Charlotte network;multimode nonadditive path cost'), (121, '121', 'Qiaoge Liu', '', 1, 0, 0, 0.0, 0.0, 'service provider;modern service;traditional service;ServiceSwitching cost;Switching Cost;available parameter;dynamic process;important role;key factor;mathematical model'), (137, '137', 'Xiaona Yan', '', 1, 0, 0, 0.0, 0.0, 'capillary tube;Critical Flux;flow characteristic;mathematical model;network model;neural network;numerical computation method;numerical solution;refrigerant flow;theoretical model'), (200, '200', 'Thair M. Hamtini', '', 1, 0, 0, 0.0, 0.0, 'computer-facilitated instruction;non-computer facilitated instruction;comparison study;developmental mathematics'), (239, '239', 'M. Garrard', '', 1, 0, 0, 0.0, 0.0, 'Computer-assisted composition;theatrical lighting;new system prototype;performance control;performance control unit;previous work;prototype development;Bell Telephone Laboratories;F. R;M. V. Mathews'), (326, '326', 'S. Rohini', '', 1, 0, 0, 0.0, 0.0, 'meeting scheduler;constraint satisfaction problem;common meeting time;meeting scheduling problem;Schedule MeetingsConstraint satisfaction problem;mathematical problem;intense research;operations research;reasonable time;artificial intelligence'), (445, '445', 'Chau Do', 'Centrum Wiskunde & Informatica, Amsterdam, The Netherlands', 1, 0, 0, 0.0, 0.0, 'clear matching solution;matching process;semantically matching concept;alignment algorithm;formal description;fuzzy nature;improved ontology alignmentOntologies;knowledge domain;mathematical nature;ontology alignment'), (545, '545', 'Donald Doan Harter', 'North Dakota State Univ. of Agriculture and Applied Science, Wahpeton', 1, 0, 0, 0.0, 0.0, 'abstract mathematical system;interval set'), (618, '618', 'Guo-liang Zou', '', 1, 0, 0, 0.0, 0.0, 'Battery Pack;service life;working life;current power system;Sea BuoyIn order;maintenance measure;mathematic model;theoretical analysis'), (665, '665', 'Frank M. Vivio', '', 1, 0, 0, 0.0, 0.0, 'Government-sponsored program;mathematics teacher')]\n",
      "[(61, '61', 'Xinping Yan', '', 1, 0, 0, 0.0, 0.0, 'GP algorithm;F-W algorithm;FW algorithm;mathematic model;traffic assignment model;different engine operating mode;different location;different network structure;Charlotte network;multimode nonadditive path cost'), (121, '121', 'Qiaoge Liu', '', 1, 0, 0, 0.0, 0.0, 'service provider;modern service;traditional service;ServiceSwitching cost;Switching Cost;available parameter;dynamic process;important role;key factor;mathematical model'), (137, '137', 'Xiaona Yan', '', 1, 0, 0, 0.0, 0.0, 'capillary tube;Critical Flux;flow characteristic;mathematical model;network model;neural network;numerical computation method;numerical solution;refrigerant flow;theoretical model'), (200, '200', 'Thair M. Hamtini', '', 1, 0, 0, 0.0, 0.0, 'computer-facilitated instruction;non-computer facilitated instruction;comparison study;developmental mathematics'), (239, '239', 'M. Garrard', '', 1, 0, 0, 0.0, 0.0, 'Computer-assisted composition;theatrical lighting;new system prototype;performance control;performance control unit;previous work;prototype development;Bell Telephone Laboratories;F. R;M. V. Mathews'), (326, '326', 'S. Rohini', '', 1, 0, 0, 0.0, 0.0, 'meeting scheduler;constraint satisfaction problem;common meeting time;meeting scheduling problem;Schedule MeetingsConstraint satisfaction problem;mathematical problem;intense research;operations research;reasonable time;artificial intelligence'), (445, '445', 'Chau Do', 'Centrum Wiskunde & Informatica, Amsterdam, The Netherlands', 1, 0, 0, 0.0, 0.0, 'clear matching solution;matching process;semantically matching concept;alignment algorithm;formal description;fuzzy nature;improved ontology alignmentOntologies;knowledge domain;mathematical nature;ontology alignment'), (545, '545', 'Donald Doan Harter', 'North Dakota State Univ. of Agriculture and Applied Science, Wahpeton', 1, 0, 0, 0.0, 0.0, 'abstract mathematical system;interval set'), (618, '618', 'Guo-liang Zou', '', 1, 0, 0, 0.0, 0.0, 'Battery Pack;service life;working life;current power system;Sea BuoyIn order;maintenance measure;mathematic model;theoretical analysis'), (665, '665', 'Frank M. Vivio', '', 1, 0, 0, 0.0, 0.0, 'Government-sponsored program;mathematics teacher')]\n"
     ]
    }
   ],
   "source": [
    "with create_connection(database_file) as conn:\n",
    "    print('query by index')\n",
    "    print(conn.cursor().execute(\"\"\"\n",
    "    SELECT * FROM authors WHERE idx=12345\n",
    "    \"\"\").fetchall())\n",
    "    print('query by tag')\n",
    "    print(conn.cursor().execute(\"\"\"\n",
    "    SELECT * FROM authors WHERE t LIKE '%math%'\n",
    "    \"\"\").fetchmany(10))\n",
    "    print(conn.cursor().execute(\"SELECT * FROM authors WHERE %s LIKE '%%'||?||'%%'\"%('t'),['math']).fetchmany(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> Explored shield, a NoSQL option for storing data, opt a very poor data compression and loading speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#index 1\n",
    "#n O. Willum\n",
    "#a Res. Center for Microperipherik, Technische Univ. Berlin, Germany\n",
    "#pc 1\n",
    "#cn 0\n",
    "#hi 0\n",
    "#pi 0.0000\n",
    "#upi 0.0000\n",
    "#t new product;product group;active product;long product lifetime;old product;product generation;new technology;environmental benefit;environmental choice;environmental consequence\n",
    "'''\n",
    "# def process_author_shelve():\n",
    "#     with open('data/AMiner-Author.txt', 'r') as file:\n",
    "#         data = file.read().split('\\n\\n')\n",
    "#\n",
    "#     with shelve.open('authors.shelve') as authors:\n",
    "#         detail = ['n', 'a', 'pc', 'cn', 'hi', 'pi', 'upi', 't']\n",
    "#         for auth in data:\n",
    "#             info = auth.split('\\n')\n",
    "#             if info[0] is '':\n",
    "#                 break\n",
    "#             index = info[0].split(' ')[1]\n",
    "#             author = {}\n",
    "#             for num,each in enumerate(detail):\n",
    "#                 author[each] = info[num+1].replace('#'+each+' ', '')\n",
    "#             author['a'] = author['a'].split(', ')\n",
    "#             author['t'] = author['t'].split(';')\n",
    "#             author['field'] = []\n",
    "#             author['field']+=([item for field in author['t'] for item in field.split(' ')])\n",
    "#             authors[index] = author\n",
    "#         return authors\n",
    "\n",
    "# authors = process_author_shelve()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
